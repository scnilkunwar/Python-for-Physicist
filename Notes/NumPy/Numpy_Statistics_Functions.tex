\documentclass[a4paper, 12pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{listings}
\geometry{a4paper, margin=1in}
\usepackage{xcolor}

\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,       % Font style for code
    keywordstyle=\bfseries\color{teal},      % Style for keywords
    stringstyle=\color{orange},              % Style for strings
    commentstyle=\color{green!50!black}\itshape, % Style for comments
    numbers=left,                            % Line numbering
    numberstyle=\tiny\color{gray},           % Style for line numbers
    stepnumber=1,                            % Increment of line numbers
    numbersep=8pt,                           % Space between numbers and code
    frame=single,                            % Frame around code
    rulecolor=\color{black},                 % Frame color
    backgroundcolor=\color{white!97!gray},   % Code background color
    breaklines=true,                         % Automatic line breaks
    captionpos=b,                            % Position of captions
    showstringspaces=false,                  % Don't show spaces in strings
    tabsize=4,                               % Tab size
    morekeywords={as, assert, async, await}, % Additional Python keywords
    xleftmargin=0.5cm                        % Left margin space
}

\title{Commonly Used NumPy Statistical Functions}
\author{Sunil Kunwar}
\date{\today}

\begin{document}

\maketitle

NumPy provides a set of functions to perform various statistical operations. Here are some commonly used NumPy statistical functions:

\section{Basic Statistics}

\subsection{ Mean (\texttt{numpy.mean})}
The mean (average) of the data can be calculated using:
\[
\text{mean\_value} = \text{np.mean(data)}
\]
\begin{lstlisting}[language=Python]
import numpy as np

data = np.array([1, 2, 3, 4, 5])
mean_value = np.mean(data)
print(mean_value)  # Output: 3.0
\end{lstlisting}

\subsection{ Median (\texttt{numpy.median})}
The median (middle value) of the data can be calculated using:
\[
\text{median\_value} = \text{np.median(data)}
\]
\begin{lstlisting}[language=Python]
median_value = np.median(data)
print(median_value)  # Output: 3.0
\end{lstlisting}

\subsection{ Standard Deviation (\texttt{numpy.std})}
The standard deviation (spread of data) can be calculated using:
\[
\text{std\_value} = \text{np.std(data)}
\]
\begin{lstlisting}[language=Python]
std_value = np.std(data)
print(std_value)  # Output: 1.4142135623730951
\end{lstlisting}

\subsection{ Variance (\texttt{numpy.var})}
The variance (measure of data spread from the mean) can be calculated using:
\[
\text{var\_value} = \text{np.var(data)}
\]
\begin{lstlisting}[language=Python]
var_value = np.var(data)
print(var_value)  # Output: 2.0
\end{lstlisting}

\subsection{ Minimum and Maximum (\texttt{numpy.min}, \texttt{numpy.max})}
The minimum and maximum values of the data can be calculated using:
\[
\text{min\_value} = \text{np.min(data)}, \quad \text{max\_value} = \text{np.max(data)}
\]
\begin{lstlisting}[language=Python]
min_value = np.min(data)
max_value = np.max(data)
print(min_value, max_value)  # Output: 1 5
\end{lstlisting}

\subsection{ Percentiles (\texttt{numpy.percentile})}
The nth percentile of the data can be calculated using:
\[
\text{percentile\_n} = \text{np.percentile(data, n)}
\]
\begin{lstlisting}[language=Python]
percentile_50 = np.percentile(data, 50)
print(percentile_50)  # Output: 3.0
\end{lstlisting}

\subsection{ Correlation Coefficient (\texttt{numpy.corrcoef})}
The correlation between two datasets can be calculated using:
\[
\text{correlation} = \text{np.corrcoef(data1, data2)}
\]
\begin{lstlisting}[language=Python]
data1 = np.array([1, 2, 3, 4])
data2 = np.array([4, 3, 2, 1])
correlation = np.corrcoef(data1, data2)
print(correlation)
\end{lstlisting}

\subsection{ Covariance (\texttt{numpy.cov})}
The covariance between two datasets can be calculated using:
\[
\text{covariance} = \text{np.cov(data1, data2)}
\]
\begin{lstlisting}[language=Python]
covariance = np.cov(data1, data2)
print(covariance)
\end{lstlisting}

\subsection{ Histogram (\texttt{numpy.histogram})}
To create a histogram and get bin edges, use:
\[
\text{hist}, \text{bin\_edges} = \text{np.histogram(data, bins=5)}
\]
\begin{lstlisting}[language=Python]
hist, bin_edges = np.histogram(data, bins=5)
print(hist, bin_edges)
\end{lstlisting}

\section{Advanced Statistics}

\subsection{ Cumulative Statistics}
\subsubsection{ Cumulative Sum}
The cumulative sum of an array can be calculated using:
\[
\text{cumulative\_sum} = \text{np.cumsum(data)}
\]
\begin{lstlisting}[language=Python]
cumulative_sum = np.cumsum(data)
\end{lstlisting}

\subsubsection{ Cumulative Product}
The cumulative product of an array can be calculated using:
\[
\text{cumulative\_product} = \text{np.cumprod(data)}
\]
\begin{lstlisting}[language=Python]
cumulative_product = np.cumprod(data)
\end{lstlisting}

\subsection{Weighted Average}
The weighted average of data with corresponding weights can be calculated using:
\[
\text{weighted\_avg} = \text{np.average(data, weights=weights)}
\]
\begin{lstlisting}[language=Python]
weights = np.array([0.1, 0.2, 0.3, 0.4, 0.5])
weighted_avg = np.average(data, weights=weights)
\end{lstlisting}

\subsection{ Running/Moving Average}
A simple moving average can be computed using:
\[
\text{moving\_avg} = \text{np.convolve(data, window, mode='valid')}
\]
\begin{lstlisting}[language=Python]
window = np.ones(3) / 3
moving_avg = np.convolve(data, window, mode='valid')
\end{lstlisting}

\section{Miscellaneous Statistics}

\subsection{ Quartiles}
Quartiles can be calculated using the 25th and 75th percentiles:
\[
\text{q1} = \text{np.percentile(data, 25)}, \quad \text{q3} = \text{np.percentile(data, 75)}
\]
\begin{lstlisting}[language=Python]
q1 = np.percentile(data, 25)
q3 = np.percentile(data, 75)
\end{lstlisting}

\subsection{Range}
The range (difference between maximum and minimum values) can be calculated using:
\[
\text{range\_value} = \text{np.ptp(data)}
\]
\begin{lstlisting}[language=Python]
range_value = np.ptp(data)
\end{lstlisting}

\end{document}
